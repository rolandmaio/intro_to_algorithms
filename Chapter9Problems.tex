\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\title{Problems Chapter 9}
\date{}

\begin{document}
\maketitle
\section*{Exercise 9.2-1}
Show that RANDOMIZED-SELECT never makes a recursive call to a 0-length array.
\vspace*{\baselineskip}
\\
Assume, to the contrary, that RANDOMIZED-SELECT does make a recursive call to a 0-length array. Then, this recursive call must occur on line 8 or 9. If it occurs on line 8, then it must be the case that $q=p$ after the call to RANDOMIZED-PARTITION on line 3. In which case, $k=1$ and $i\neq 1$, since otherwise we would have returned $A[q]$ on line 6. But since, $k=1\neq i$, it cannot be the case that $i<k$ and so the recursive call to RANDOMIZED-SELEECT on line 8 is not executed. But this contradicts our assumption. Otherwise, the recursive call to RANDOMIZED-SELECT to a 0-length array must occur on line 9. In which case we must have $q=r$. By similar reasoning as above, however, if $q=r$, then we must have $i<k$ and so the recursive call on line 9 cannot possibly execute. Therefore, RANDOMIZED-SELECT does not make a recursive call to a 0-length array.

\section*{Exercise 9.2-2}
Argue that the indicator random variable $X_k$ and the value $T(\textit{max}(k-1,n-k))$ are independent.
\vspace*{\baselineskip}
\\
Consider the the expression $\textit{max}(k-1, n-k)$ which is defined as
\begin{equation}
\textit{max}(k-1,n-k)=\begin{cases}
	k-1 & \text{if } k > \lceil n/2\rceil\\
	n-k & \text{if } k \leq \lceil n/2\rceil
	\end{cases}
\end{equation}
and let $Y$ be the random variable that is the value of $\textit{max}(k-1,n-k)$. Observe, that $P\lbrace Y=k-1\rbrace = P\lbrace k > \lceil n/2 \rceil\rbrace = \frac{n-\lceil n/2\rceil}{n}$. This probability is independent of the value of $k$. And since $P\lbrace Y=n-k\rbrace = 1 - P\lbrace Y=k-1\rbrace$ we conclude that the random variable $Y$ is independent of the value of $k$ for all $k$. And since $X_k$ is entirely dependent on this quantity, it follows that $Y$ is independent of $X_k$ and finally that the random variables $X_k$ and the value $T(\textit{max}(k-1,n-k))$ are independent.

\section*{Exercise 9.3-2}
Analyze SELECT to show that if $n\geq 140$, then at least $\lceil n/4\rceil$ elements are greater than the median-of-medians $x$ and at least $\lceil n/4\rceil$ elements are less than $x$.
\vspace*{\baselineskip}
\\
The analysis in the text has shown that for any median-of-medians, $x$, and sufficiently large $n$, the number of elements greater than $x$ is at least $\frac{3n}{10}-6$. The same analysis, except considering the elements that are less than $x$, will show that the lower bound for the number of elements less than $x$ is the same. Using this lower bound, we may write the following inequality
\begin{equation}
\lceil n/4 \rceil \leq \frac{n}{4} + 1 \leq \frac{3n}{10} - 6
\end{equation}
whose solution is $n\geq 140$.

% This was me solving the inequality in latex, it would be clutter in the actual document.
%\begin{equation}
%\begin{split}
%\frac{n}{4} + 1 &\leq \frac{3n}{10} - 6 \\
%\frac{n}{4} - \frac{3n}{10} &\leq -7 \\
%n(\frac{1}{4} - \frac{3}{10}) &\leq -7 \\
%n(\frac{5}{20} - \frac{6}{20}) &\leq -7 \\
%n(\frac{-1}{20}) &\leq -7 \\
%n &\geq 140
%\end{split}
%\end{equation}

\section*{Exercise 9.3-3}
Show how quicksort can be made to run in $O(n\text{ lg }n)$ time in the worst case, assuming that all elements are distinct.
\vspace*{\baselineskip}
\\
The worst case running time of quicksort of $\Theta (n^2)$ occurs when the pivot element in the call to PARTITION is either the smallest element in the array, or the greatest element in the array. In other words, the worst case occurs when the pivot is either the $1$st order statistic, or it is the $n$th order statistic. By using the technique of finding the median-of-medians introduced in this chapter, we can guarantee that PARTITION will use a good pivot.
\vspace*{\baselineskip}
\\
We change the call to PARTITION to choose the pivot by first calling SELECT on the lower median of the array, $\lceil (r-p)/2\rceil$. The call to select occurs only once, and takes time $O(n)$. Thus, the overall running time of partition of $\Theta (n)$ is unchanged. Thus, the sizes of the subproblems produced by PARTITION are $O(n/2)$. Therefore, we may bound the resulting recurrence relation as follows
\begin{equation}
T(n) \leq 2T(n/2) + O(n)
\end{equation}
whose solution, by the master theorem, is $T(n)=O(n\text{ lg }n)$.

\section*{Exercise 9.3-4}
Suppose that an algorithm uses only comparisons to find the $i$th smallest element in a set of $n$ elements. Show that it can also find the $i-1$ smaller elements and the $n-i$ larger elements without performing any additional comparisons.
\vspace*{\baselineskip}
\\
In order to find the $i$th smallest element, the algorithm must partition the elements into the $i-1$ that are less than the $i$th smallest element, and the $n-i$ that are greater. Since the algorithm only uses comparisons, it must, in the process of partitioning the elements, identify each one. By keeping track of which partition each element is assigned as they are assigned, the algorithm can find the $i-1$ smaller elements and the $n-i$ larger elements without performing any additional comparisons.

\section*{Exercise 9.3-5}
Suppose that you have a "black-box" worst-case linear-time median subroutine. Give a simple linear-time algorithm that solves the selection problem for an arbitrary order statistic.
\vspace*{\baselineskip}
\\
Let $A$ be the input array of $n$ elements, $k$ be the median of $n$ and $i$ be the order statistic we wish to find. The algorithm is as follows. Run the linear-time median subroutine on the input. If $i==k$, then we are done. Otherwise, if $i<k$, discard those elements of $A$ that are greater than or equal to $k$ and recursively call this algorithm on the remaining elements. If $i>k$, discard those elements of $A$ that are less than or equal to $k$ and recursively call the algorithm on the remaining elements, setting $i=i-k$. Assuming that the elements of the array are distinct, each iteration will result in a subproblem of size that is $O(n/2)$. Additionally, the filtering can be done in lienear time. Therefore, the recurrence relation of this algorithm can be bounded by
\begin{equation}
T(n) \leq T(n/2) + O(n)
\end{equation}
and the solution of this recurrence, by the master theorem, is $T(n) = O(n)$.

\section*{Exercise 9.3-6}
The $k$th \textbf{\textit{quantiles}} of an $n$-element set are the $k-1$ order statistics that divide the sorted set into $k$ equal-sized sets (to within 1). Give an $O(n\text{ lg } k)$-time algorithm to list the $k$th quantiles of a set.
\vspace*{\baselineskip}
\\
Let $m_k$ be the median of the elements in the $k$th quantile. We can determine the order statistic with respect to $n$ of $m_k$ in constant time. This is simply $o_n(m_k)=\lceil\frac{k-1}{2}\rceil\lceil\frac{n}{k}\rceil$. We can use this as the basis of the desired algorithm, call it KQUANTILE. Call SELECT on the input array $A$ with $i=o_n(m_k)$. Store the element that is returned, and then recursively call KQUANTILE on the subarray $A[1..o_n(m_k)-1]$ with a new $k=\lceil\frac{k-1}{2}\rceil$. And recursively call KQUANTILE on the subarray $A[o_n(m_k)+1..n]$ with a new $k$ defined as:
\begin{align*}
	k=\begin{cases}
		\lceil\frac{k-1}{2}\rceil & \text{ if } k \equiv 0 \mod 2 \\
		\lceil\frac{k-1}{2}\rceil + 1 & \text{ if } k \equiv 1 \mod 2
	\end{cases}
\end{align*}
Each recursive call of KQUANTILE will work on the entire array and so run in time $O(n)$. But each level of recursion will find 2 times as many of the elements in the $k$th quantile as the last. Consequently, there will be at most $O(\text{lg }k)$ recursive calls. Hence the running time of KQUANTILE is $O(n\text{ lg }k)$.

\section*{Exercise 9.3-7}
Describe an $O(n)$-time algorithm that, given a set $S$ of $n$ distinct numbers and a positive integer $k\leq n$, determines the $k$ numbers in $S$ that are closest to the median of $S$.
\vspace*{\baselineskip}
\\
Let $m$ be the order statistic of the median. Use SELECT to find the median and the $m-k$ and $m+k$ order statistics of $S$. Do a linear scan over these elements computing the absolute value of their difference with the median. Initialize pointers to the $m+1$ and $m-1$ order statistics. Compare them, take the lesser, and move its pointer to the next element. Repeat until the $k$ closest elements have been found. The $m$, $m+k$th and $m-k$th order statistics can be found in linear time. The absolute value of the difference between the elements and the median may also be found in time that is $O(n)$, since $k=O(n)$, and the final comparison and selection of elements can also be done in time $O(n)$. Therefore the algorithm runs in $O(n)$-time.

\section*{Exercise 9.3-8}
Let $X[1..n]$ and $Y[1..n]$ be two arrays, each containing $n$ numbers already in sorted order. Give an $O(\text{lg }n)$-time algorithm to find the median of all $2n$ elements in arrays $X$ and $Y$.
\vspace*{\baselineskip}
\\
\begin{algorithm}
\caption{My algorithm}\label{word}
\begin{algorithmic}
\Function{SELECTUNION}{X, Y, i}
	\State $m_x=$ median of $X$
	\State $m_y$ = median of $Y$
	\If{$m_x<m_y$}
		\If{$o_X(m_x) + o_Y(m_y) < i$}
			\State{$q=$ SELECTUNION($X[m_x+1..X.n]$, $Y$, $i-o(m_x)$)}
		\Else
			\State{$q=$ SELECTUNION(}
		\EndIf
	\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\end{document}